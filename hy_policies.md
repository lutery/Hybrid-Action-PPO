# #codebase èƒ½è®²è§£ä¸€ä¸‹net_archå‚æ•°ç ï¼Ÿ
Using "Codebase"

Searched text for `net_arch`, 35 results

Read [](file:///c%3A/Projects/OpenSource/python/Hybrid-Action-PPO/hyper_layer.py)

Read [](file:///c%3A/Projects/OpenSource/python/Hybrid-Action-PPO/hy_policies.py#318-318), lines 318 to 368

Read [](file:///c%3A/Projects/OpenSource/python/Hybrid-Action-PPO/hy_policies.py#358-358), lines 358 to 378

Read [](file:///c%3A/Projects/OpenSource/python/Hybrid-Action-PPO/hy_policies.py#395-395), lines 395 to 425

# `net_arch` å‚æ•°è¯¦è§£

## æ¦‚è¿°

`net_arch` æ˜¯ç”¨äºå®šä¹‰**ç­–ç•¥ç½‘ç»œå’Œä»·å€¼ç½‘ç»œæ¶æ„**çš„å‚æ•°ï¼Œå®ƒæ§åˆ¶ç¥ç»ç½‘ç»œçš„å±‚æ•°å’Œæ¯å±‚çš„ç¥ç»å…ƒæ•°é‡ã€‚

## å‚æ•°ç±»å‹

`net_arch` æ”¯æŒä¸¤ç§æ ¼å¼ï¼š

### 1. å­—å…¸æ ¼å¼ï¼ˆæ¨èï¼‰

````python
net_arch = dict(
    pi=[64, 64],  # ç­–ç•¥ç½‘ç»œï¼ˆpolicy networkï¼‰çš„éšè—å±‚
    vf=[64, 64]   # ä»·å€¼ç½‘ç»œï¼ˆvalue function networkï¼‰çš„éšè—å±‚
)
````

- **`pi`**ï¼šç­–ç•¥ç½‘ç»œçš„å±‚ç»“æ„ï¼Œæ§åˆ¶åŠ¨ä½œè¾“å‡º
- **`vf`**ï¼šä»·å€¼ç½‘ç»œçš„å±‚ç»“æ„ï¼Œæ§åˆ¶çŠ¶æ€ä»·å€¼ä¼°è®¡

### 2. åˆ—è¡¨æ ¼å¼

````python
net_arch = [128, 128]  # ç­–ç•¥å’Œä»·å€¼ç½‘ç»œå…±äº«ç›¸åŒçš„æ¶æ„
````

å½“ä½¿ç”¨åˆ—è¡¨æ—¶ï¼Œç­–ç•¥ç½‘ç»œå’Œä»·å€¼ç½‘ç»œä¼šä½¿ç”¨**ç›¸åŒçš„å±‚ç»“æ„**ã€‚

## åœ¨ä»£ç ä¸­çš„å¤„ç†

æŸ¥çœ‹ [`hy_policies.py:348-364`](hy_policies.py ) çš„å¤„ç†é€»è¾‘ï¼š

````python
# æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ—§æ ¼å¼ï¼ˆåˆ—è¡¨åŒ…è£¹å­—å…¸ï¼‰
if isinstance(net_arch, list) and len(net_arch) > 0 and isinstance(net_arch[0], dict):
    warnings.warn(
        "è¯·ç›´æ¥ä¼ é€’å­—å…¸è€Œä¸æ˜¯åˆ—è¡¨ "
        "(net_arch=dict(pi=..., vf=...) è€Œä¸æ˜¯ net_arch=[dict(pi=..., vf=...)])"
    )
    net_arch = net_arch[0]  # æå–å­—å…¸

# è®¾ç½®é»˜è®¤å€¼
if net_arch is None:
    if features_extractor_class == NatureCNN:
        net_arch = []  # å¯¹äºCNNï¼Œä¸éœ€è¦é¢å¤–çš„MLPå±‚
    else:
        net_arch = dict(pi=[64, 64], vf=[64, 64])  # é»˜è®¤ï¼šä¸¤å±‚64ç¥ç»å…ƒ
````

## åœ¨ `HyMlpExtractor` ä¸­çš„åº”ç”¨

æŸ¥çœ‹ [`hyper_layer.py:24-29`](hyper_layer.py ) ä¸­å¦‚ä½•è§£æ `net_arch`ï¼š

````python
if isinstance(net_arch, dict):
    pi_layers_dims = net_arch.get("pi", [])  # ç­–ç•¥ç½‘ç»œå±‚çš„å¤§å°
    vf_layers_dims = net_arch.get("vf", [])  # ä»·å€¼ç½‘ç»œå±‚çš„å¤§å°
else:
    # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œç­–ç•¥å’Œä»·å€¼ç½‘ç»œä½¿ç”¨ç›¸åŒçš„ç»“æ„
    pi_layers_dims = vf_layers_dims = net_arch
````

## åœ¨æ··åˆåŠ¨ä½œç©ºé—´ä¸­çš„ç‰¹æ®Šå¤„ç†

åœ¨ HPPO ä¸­ï¼Œç­–ç•¥ç½‘ç»œè¢«**åˆ†æˆä¸¤ä¸ªå¤´**ï¼š

````python
# åœ¨ hyper_layer.py ä¸­
for curr_layer_dim in pi_layers_dims:
    # è¿ç»­åŠ¨ä½œç­–ç•¥ç½‘ç»œ
    policy_net_con.append(nn.Linear(last_layer_dim_pi, curr_layer_dim))
    policy_net_con.append(activation_fn())
    
    # ç¦»æ•£åŠ¨ä½œç­–ç•¥ç½‘ç»œï¼ˆç›¸åŒçš„ç»“æ„ï¼‰
    policy_net_disc.append(nn.Linear(last_layer_dim_pi, curr_layer_dim))
    policy_net_disc.append(activation_fn())
    
    last_layer_dim_pi = curr_layer_dim
````

**å…³é”®ç‚¹**ï¼š
- **è¿ç»­åŠ¨ä½œ**å’Œ**ç¦»æ•£åŠ¨ä½œ**åˆ†åˆ«æ‹¥æœ‰ç‹¬ç«‹çš„ç­–ç•¥ç½‘ç»œ
- ä¸¤ä¸ªç½‘ç»œçš„**å±‚ç»“æ„ç›¸åŒ**ï¼Œä½†**å‚æ•°ç‹¬ç«‹**
- ä»·å€¼ç½‘ç»œæ˜¯å…±äº«çš„ï¼Œåªæœ‰ä¸€ä¸ª

## ç½‘ç»œç»“æ„ç¤ºæ„å›¾

````
è¾“å…¥è§‚å¯Ÿ (observation)
    â†“
ç‰¹å¾æå–å™¨ (features_extractor)
    â†“
ç‰¹å¾å‘é‡ (features)
    â”œâ”€â†’ è¿ç»­åŠ¨ä½œç­–ç•¥ç½‘ç»œ (policy_net_con) [64, 64] â†’ è¿ç»­åŠ¨ä½œåˆ†å¸ƒ
    â”œâ”€â†’ ç¦»æ•£åŠ¨ä½œç­–ç•¥ç½‘ç»œ (policy_net_disc) [64, 64] â†’ ç¦»æ•£åŠ¨ä½œåˆ†å¸ƒ
    â””â”€â†’ ä»·å€¼ç½‘ç»œ (value_net) [64, 64] â†’ çŠ¶æ€ä»·å€¼
````

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼šé»˜è®¤é…ç½®

````python
model = HyPPO(
    policy="MlpPolicy",
    env=env,
    # ä¸æŒ‡å®š net_archï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼šdict(pi=[64, 64], vf=[64, 64])
)
````

### ç¤ºä¾‹ 2ï¼šè‡ªå®šä¹‰ç‹¬ç«‹ç½‘ç»œ

````python
policy_kwargs = dict(
    net_arch=dict(
        pi=[256, 256, 128],  # ç­–ç•¥ç½‘ç»œï¼š3å±‚ï¼Œé€æ¸å‡å°
        vf=[128, 128]        # ä»·å€¼ç½‘ç»œï¼š2å±‚ï¼Œè¾ƒå°
    )
)

model = HyPPO(
    policy="MlpPolicy",
    env=env,
    policy_kwargs=policy_kwargs
)
````

**åŸå› **ï¼šç­–ç•¥ç½‘ç»œé€šå¸¸éœ€è¦æ›´å¤æ‚çš„ç»“æ„æ¥å­¦ä¹ åŠ¨ä½œåˆ†å¸ƒï¼Œä»·å€¼ç½‘ç»œç›¸å¯¹ç®€å•ã€‚

### ç¤ºä¾‹ 3ï¼šå…±äº«ç½‘ç»œç»“æ„

````python
policy_kwargs = dict(
    net_arch=[128, 128]  # ç­–ç•¥å’Œä»·å€¼ç½‘ç»œä½¿ç”¨ç›¸åŒçš„ç»“æ„
)

model = HyPPO(
    policy="MlpPolicy",
    env=env,
    policy_kwargs=policy_kwargs
)
````

### ç¤ºä¾‹ 4ï¼šæ·±åº¦ç½‘ç»œ

````python
policy_kwargs = dict(
    net_arch=dict(
        pi=[512, 256, 128, 64],  # 4å±‚æ·±åº¦ç­–ç•¥ç½‘ç»œ
        vf=[256, 128]            # 2å±‚ä»·å€¼ç½‘ç»œ
    )
)

model = HyPPO(
    policy="MlpPolicy",
    env=env,
    policy_kwargs=policy_kwargs
)
````

## ä¸å…¶ä»–å‚æ•°çš„å…³ç³»

### 1. ä¸ `activation_fn` çš„é…åˆ

````python
policy_kwargs = dict(
    net_arch=dict(pi=[128, 128], vf=[128, 128]),
    activation_fn=th.nn.ReLU  # æ¯å±‚åé¢æ·»åŠ  ReLU æ¿€æ´»
)
````

### 2. ä¸ç‰¹å¾æå–å™¨çš„é…åˆ

````python
# å¯¹äºå›¾åƒè¾“å…¥ï¼Œä½¿ç”¨ CNN ç‰¹å¾æå–å™¨åï¼Œé€šå¸¸ä¸éœ€è¦æ·±å±‚ MLP
policy_kwargs = dict(
    features_extractor_class=NatureCNN,
    net_arch=[]  # CNN åä¸éœ€è¦é¢å¤–çš„ MLP å±‚
)

# å¯¹äºå‘é‡è¾“å…¥ï¼Œéœ€è¦æ›´æ·±çš„ MLP
policy_kwargs = dict(
    features_extractor_class=FlattenExtractor,
    net_arch=dict(pi=[256, 256], vf=[128, 128])
)
````

## è®¾è®¡åŸåˆ™

### 1. ç½‘ç»œæ·±åº¦é€‰æ‹©

| ä»»åŠ¡å¤æ‚åº¦ | æ¨èå±‚æ•° | ç¤ºä¾‹ |
|-----------|---------|------|
| ç®€å•ä»»åŠ¡ | 1-2å±‚ | `[64]` æˆ– `[64, 64]` |
| ä¸­ç­‰ä»»åŠ¡ | 2-3å±‚ | `[128, 128]` æˆ– `[256, 128, 64]` |
| å¤æ‚ä»»åŠ¡ | 3-4å±‚ | `[512, 256, 128, 64]` |

### 2. ç­–ç•¥ vs ä»·å€¼ç½‘ç»œ

````python
# å¸¸è§æ¨¡å¼ï¼šç­–ç•¥ç½‘ç»œæ›´æ·±
net_arch = dict(
    pi=[256, 256, 128],  # ç­–ç•¥éœ€è¦å­¦ä¹ å¤æ‚çš„åŠ¨ä½œåˆ†å¸ƒ
    vf=[128, 128]        # ä»·å€¼åªéœ€è¦ä¼°è®¡æ ‡é‡å€¼
)
````

### 3. å‚æ•°é‡è€ƒè™‘

````python
# è®¡ç®—å‚æ•°é‡ç¤ºä¾‹
# å‡è®¾è¾“å…¥ç‰¹å¾ç»´åº¦ä¸º 10ï¼ŒåŠ¨ä½œç©ºé—´ç»´åº¦ä¸º 4
net_arch = [64, 64]

# ç¬¬ä¸€å±‚ï¼š10 * 64 + 64 = 704
# ç¬¬äºŒå±‚ï¼š64 * 64 + 64 = 4160
# è¾“å‡ºå±‚ï¼š64 * 4 + 4 = 260
# æ€»è®¡ï¼šçº¦ 5000 å‚æ•°

# å¦‚æœæ”¹ä¸º [256, 256]
# æ€»è®¡ï¼šçº¦ 80000 å‚æ•°ï¼ˆå¢åŠ 16å€ï¼‰
````

## è°ƒè¯•æŠ€å·§

### 1. æ‰“å°ç½‘ç»œç»“æ„

````python
model = HyPPO("MlpPolicy", env, policy_kwargs=dict(net_arch=dict(pi=[128, 128], vf=[64, 64])))

# æ‰“å°ç­–ç•¥ç½‘ç»œç»“æ„
print(model.policy.mlp_extractor.policy_net_con)
print(model.policy.mlp_extractor.policy_net_disc)

# æ‰“å°ä»·å€¼ç½‘ç»œç»“æ„
print(model.policy.mlp_extractor.value_net)
````

### 2. éªŒè¯è¾“å‡ºç»´åº¦

````python
# åœ¨ hyper_layer.py çš„ __init__ æœ€åæ·»åŠ 
print(f"ç­–ç•¥ç½‘ç»œè¾“å‡ºç»´åº¦: {self.latent_dim_pi}")
print(f"ä»·å€¼ç½‘ç»œè¾“å‡ºç»´åº¦: {self.latent_dim_vf}")
````

## å¸¸è§é”™è¯¯

### âŒ é”™è¯¯ 1ï¼šä½¿ç”¨æ—§æ ¼å¼

````python
# æ—§æ ¼å¼ï¼ˆä¼šè§¦å‘è­¦å‘Šï¼‰
net_arch = [dict(pi=[64, 64], vf=[64, 64])]

# âœ… æ­£ç¡®æ ¼å¼
net_arch = dict(pi=[64, 64], vf=[64, 64])
````

### âŒ é”™è¯¯ 2ï¼šç½‘ç»œè¿‡æ·±å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±

````python
# å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š
net_arch = dict(pi=[512, 512, 512, 512, 512], vf=[512, 512, 512])

# âœ… å»ºè®®ä½¿ç”¨é€‚åº¦çš„æ·±åº¦
net_arch = dict(pi=[256, 128, 64], vf=[128, 64])
````

### âŒ é”™è¯¯ 3ï¼šç½‘ç»œè¿‡å°

````python
# å¯¹äºå¤æ‚ä»»åŠ¡å¯èƒ½ä¸å¤Ÿ
net_arch = dict(pi=[16], vf=[16])

# âœ… è‡³å°‘ä½¿ç”¨ 64 ç¥ç»å…ƒ
net_arch = dict(pi=[64, 64], vf=[64, 64])
````

## æ€»ç»“

- **`net_arch`** å®šä¹‰äº†ç­–ç•¥å’Œä»·å€¼ç½‘ç»œçš„éšè—å±‚ç»“æ„
- åœ¨ HPPO ä¸­ï¼Œç­–ç•¥ç½‘ç»œè¢«åˆ†æˆ**è¿ç»­åŠ¨ä½œ**å’Œ**ç¦»æ•£åŠ¨ä½œ**ä¸¤ä¸ªç‹¬ç«‹çš„ç½‘ç»œ
- æ¨èä½¿ç”¨ **`dict` æ ¼å¼**æ˜ç¡®æŒ‡å®š `pi` å’Œ `vf` çš„ç»“æ„
- é»˜è®¤å€¼æ˜¯ `dict(pi=[64, 64], vf=[64, 64])`ï¼Œé€‚ç”¨äºå¤§å¤šæ•°ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡
- å¯ä»¥æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è°ƒæ•´å±‚æ•°å’Œç¥ç»å…ƒæ•°é‡ï¼Œä½†è¦æ³¨æ„é¿å…è¿‡æ‹Ÿåˆå’Œè®­ç»ƒä¸ç¨³å®š

# #codebase make_features_extractoræ—¶å†åšä»€ä¹ˆï¼Ÿ
Optimizing tool selection...

Using "Codebase"

è®©æˆ‘æœç´¢å¹¶åˆ†æ `make_features_extractor` æ–¹æ³•åœ¨ä»£ç åº“ä¸­çš„å®ç°å’Œä½¿ç”¨ã€‚ 

Searched text for `make_features_extractor`, 3 results

Read [](file:///Users/yanghui/projects/opensource/python/Hybrid-Action-PPO/hy_policies.py#70-70), lines 70 to 110

Read [](file:///Users/yanghui/projects/opensource/python/Hybrid-Action-PPO/hy_policies.py#360-360), lines 360 to 400

Read [](file:///Users/yanghui/projects/opensource/python/Hybrid-Action-PPO/hy_policies.py#30-30), lines 30 to 60

ç°åœ¨è®©æˆ‘æŸ¥çœ‹ä¸åŒçš„ features extractor ç±»ï¼š 

Searched text for `FlattenExtractor`, 6 results

Read [](file:///Users/yanghui/projects/opensource/python/Hybrid-Action-PPO/hy_policies.py#395-395), lines 395 to 450

è®©æˆ‘æŸ¥çœ‹å®é™…ä½¿ç”¨åœºæ™¯ï¼š 

Read [](file:///Users/yanghui/projects/opensource/python/Hybrid-Action-PPO/hy_policies.py#475-475), lines 475 to 520

ç°åœ¨è®©æˆ‘å®Œæ•´åœ°è§£é‡Š `make_features_extractor` çš„ä½œç”¨ï¼š

# `make_features_extractor` æ–¹æ³•è¯¦è§£

## æ–¹æ³•å®šä¹‰ï¼ˆ`hy_policies.py:92-94`ï¼‰

```python
def make_features_extractor(self) -> BaseFeaturesExtractor:
    """Helper method to create a features extractor."""
    return self.features_extractor_class(self.observation_space, **self.features_extractor_kwargs)
```

## æ ¸å¿ƒä½œç”¨

`make_features_extractor` æ˜¯ä¸€ä¸ª**å·¥å‚æ–¹æ³•**ï¼Œè´Ÿè´£æ ¹æ®é…ç½®åˆ›å»ºç‰¹å¾æå–å™¨å®ä¾‹ã€‚å®ƒåœ¨ç¥ç»ç½‘ç»œåˆå§‹åŒ–æ—¶è¢«è°ƒç”¨ï¼Œå°†åŸå§‹è§‚å¯Ÿè½¬æ¢ä¸ºç‰¹å¾å‘é‡ã€‚

## å®Œæ•´æµç¨‹

### 1ï¸âƒ£ **åˆå§‹åŒ–é˜¶æ®µ**ï¼ˆåœ¨ `HyActorCriticPolicy.__init__` ä¸­ï¼‰

```python
# hy_policies.py:375
self.features_extractor = self.make_features_extractor()
self.features_dim = self.features_extractor.features_dim  # è·å–ç‰¹å¾ç»´åº¦
```

**å…³é”®ç‚¹**ï¼š
- ä½¿ç”¨å­˜å‚¨çš„ `features_extractor_class`ï¼ˆé»˜è®¤æ˜¯ `FlattenExtractor`ï¼‰
- ä¼ å…¥ `observation_space` å’Œé¢å¤–çš„ `features_extractor_kwargs`
- è¿”å›ä¸€ä¸ªå¯è°ƒç”¨çš„ PyTorch æ¨¡å—

### 2ï¸âƒ£ **ç‰¹å¾æå–å™¨çš„ç±»å‹**

é¡¹ç›®æ”¯æŒå¤šç§ç‰¹å¾æå–å™¨ï¼ˆä» `stable_baselines3.common.torch_layers` å¯¼å…¥ï¼‰ï¼š

| æå–å™¨ç±»å‹ | é€‚ç”¨åœºæ™¯ | è¾“å‡ºè¯´æ˜ |
|-----------|---------|---------|
| **FlattenExtractor**ï¼ˆé»˜è®¤ï¼‰ | ä¸€ç»´å‘é‡è§‚å¯Ÿç©ºé—´ | å°†è§‚å¯Ÿå±•å¹³ä¸ºä¸€ç»´å‘é‡ |
| **NatureCNN** | å›¾åƒè§‚å¯Ÿç©ºé—´ï¼ˆAtariæ¸¸æˆï¼‰ | ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæå–å›¾åƒç‰¹å¾ |
| **CombinedExtractor** | Dictè§‚å¯Ÿç©ºé—´ï¼ˆå¤šæ¨¡æ€è¾“å…¥ï¼‰ | ä¸ºæ¯ç§è¾“å…¥ç±»å‹ä½¿ç”¨ä¸åŒçš„æå–å™¨ |

### 3ï¸âƒ£ **åœ¨å‰å‘ä¼ æ’­ä¸­çš„ä½¿ç”¨**

#### æ­¥éª¤Aï¼šæå–ç‰¹å¾ï¼ˆ`hy_policies.py:475`ï¼‰
```python
def forward(self, obs: th.Tensor, deterministic: bool = False):
    # 1. ä»åŸå§‹è§‚å¯Ÿä¸­æå–ç‰¹å¾
    features = self.extract_features(obs)  # è°ƒç”¨ features_extractor
    
    # 2. å°†ç‰¹å¾ä¼ å…¥ä¸‰å¤´ç½‘ç»œ
    latent_pi_disc, latent_pi_con, latent_vf = self.mlp_extractor(features)
    
    # 3. ç”ŸæˆåŠ¨ä½œå’Œä»·å€¼
    values = self.value_net(latent_vf)
    distribution_disc = self._get_action_dist_from_latent_disc(latent_pi_disc)
    distribution_con = self._get_action_dist_from_latent_con(latent_pi_con)
    ...
```

#### æ­¥éª¤Bï¼šextract_features å†…éƒ¨å®ç°ï¼ˆ`hy_policies.py:96-105`ï¼‰
```python
def extract_features(self, obs: th.Tensor, features_extractor: BaseFeaturesExtractor) -> th.Tensor:
    """
    é¢„å¤„ç†è§‚å¯Ÿå¹¶æå–ç‰¹å¾
    """
    # 1. é¢„å¤„ç†ï¼ˆå½’ä¸€åŒ–å›¾åƒç­‰ï¼‰
    preprocessed_obs = preprocess_obs(obs, self.observation_space, normalize_images=self.normalize_images)
    
    # 2. é€šè¿‡ç‰¹å¾æå–å™¨
    return features_extractor(preprocessed_obs)  # è°ƒç”¨ __call__ æ–¹æ³•
```

## å®é™…å·¥ä½œç¤ºä¾‹

### åœºæ™¯1ï¼šç®€å•å‘é‡è§‚å¯Ÿï¼ˆä½¿ç”¨ FlattenExtractorï¼‰

```python
# Sliding-v0 ç¯å¢ƒç¤ºä¾‹
observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(4,), dtype=np.float32)

# make_features_extractor åˆ›å»ºçš„æå–å™¨
features_extractor = FlattenExtractor(observation_space)

# è¾“å…¥è¾“å‡º
obs = th.tensor([[1.0, 2.0, 3.0, 4.0]])  # shape: (1, 4)
features = features_extractor(obs)        # shape: (1, 4) - ç›´æ¥å±•å¹³ï¼Œæ— å˜åŒ–
```

**FlattenExtractor åšä»€ä¹ˆ**ï¼š
- å¯¹äºå·²ç»æ˜¯å‘é‡çš„è§‚å¯Ÿï¼Œç›´æ¥è¿”å›
- å¯¹äºå¤šç»´è§‚å¯Ÿï¼ˆå¦‚ (84, 84, 4)ï¼‰ï¼Œå±•å¹³ä¸ºä¸€ç»´

### åœºæ™¯2ï¼šå›¾åƒè§‚å¯Ÿï¼ˆä½¿ç”¨ NatureCNNï¼‰

```python
# Atari ç¯å¢ƒç¤ºä¾‹
observation_space = spaces.Box(low=0, high=255, shape=(84, 84, 4), dtype=np.uint8)

# åœ¨ policy_kwargs ä¸­æŒ‡å®š
policy_kwargs = {
    "features_extractor_class": NatureCNN,
    "features_extractor_kwargs": {"features_dim": 512}
}

# make_features_extractor åˆ›å»ºçš„æå–å™¨
features_extractor = NatureCNN(observation_space, features_dim=512)

# è¾“å…¥è¾“å‡º
obs = th.tensor(np.random.randint(0, 255, (1, 4, 84, 84)))  # shape: (1, 4, 84, 84)
features = features_extractor(obs)                           # shape: (1, 512)
```

**NatureCNN åšä»€ä¹ˆ**ï¼š
- 3ä¸ªå·ç§¯å±‚ + ReLUæ¿€æ´»
- æœ€åå±•å¹³å¹¶é€šè¿‡å…¨è¿æ¥å±‚
- å°†é«˜ç»´å›¾åƒå‹ç¼©ä¸ºå›ºå®šç»´åº¦çš„ç‰¹å¾å‘é‡

### åœºæ™¯3ï¼šå¤šæ¨¡æ€è§‚å¯Ÿï¼ˆä½¿ç”¨ CombinedExtractorï¼‰

```python
# æœºå™¨äººæ§åˆ¶ç¯å¢ƒç¤ºä¾‹
observation_space = spaces.Dict({
    'image': spaces.Box(0, 255, (64, 64, 3), dtype=np.uint8),
    'vector': spaces.Box(-1, 1, (10,), dtype=np.float32)
})

# make_features_extractor è‡ªåŠ¨åˆ›å»º
features_extractor = CombinedExtractor(observation_space)

# è¾“å…¥è¾“å‡º
obs = {
    'image': th.randn(1, 3, 64, 64),
    'vector': th.randn(1, 10)
}
features = features_extractor(obs)  # shape: (1, image_features_dim + 10)
```

**CombinedExtractor åšä»€ä¹ˆ**ï¼š
- ä¸º 'image' ä½¿ç”¨ NatureCNN
- ä¸º 'vector' ä½¿ç”¨ FlattenExtractor
- å°†æ‰€æœ‰ç‰¹å¾æ‹¼æ¥èµ·æ¥

## æ•°æ®æµå›¾

```
åŸå§‹è§‚å¯Ÿ (Raw Observation)
    â†“
preprocess_obs (å½’ä¸€åŒ–/è½¬æ¢)
    â†“
features_extractor (ç‰¹å¾æå–å™¨) â† make_features_extractor() åˆ›å»º
    â†“
ç‰¹å¾å‘é‡ (Feature Vector)
    â†“
mlp_extractor (ä¸‰å¤´ç½‘ç»œ)
    â†“
    â”œâ”€â†’ latent_pi_disc â†’ action_net_disc â†’ ç¦»æ•£åŠ¨ä½œ
    â”œâ”€â†’ latent_pi_con  â†’ action_net_con  â†’ è¿ç»­åŠ¨ä½œ
    â””â”€â†’ latent_vf      â†’ value_net       â†’ ä»·å€¼ä¼°è®¡
```

## ä¸ºä»€ä¹ˆéœ€è¦ make_features_extractorï¼Ÿ

### 1. **çµæ´»æ€§**
ç”¨æˆ·å¯ä»¥é€šè¿‡ `policy_kwargs` è½»æ¾åˆ‡æ¢ä¸åŒçš„ç‰¹å¾æå–å™¨ï¼š

```python
# ç¤ºä¾‹ï¼šä¸ºå›¾åƒç¯å¢ƒä½¿ç”¨è‡ªå®šä¹‰CNN
model = HyPPO(
    "CnnPolicy",
    env,
    policy_kwargs={
        "features_extractor_class": NatureCNN,
        "features_extractor_kwargs": {"features_dim": 256}
    }
)
```

### 2. **å»¶è¿Ÿåˆ›å»º**
åœ¨ `_update_features_extractor` ä¸­ï¼Œå¦‚æœéœ€è¦å…±äº«ç‰¹å¾æå–å™¨ï¼Œå¯ä»¥ä¼ å…¥å·²åˆ›å»ºçš„å®ä¾‹ï¼›å¦åˆ™è°ƒç”¨ `make_features_extractor` åˆ›å»ºæ–°çš„ï¼š

```python
# hy_policies.py:70-89
def _update_features_extractor(self, net_kwargs, features_extractor=None):
    if features_extractor is None:
        # æ²¡æœ‰å…±äº«çš„æå–å™¨ï¼Œåˆ›å»ºæ–°çš„
        features_extractor = self.make_features_extractor()
    net_kwargs.update({
        'features_extractor': features_extractor,
        'features_dim': features_extractor.features_dim
    })
    return net_kwargs
```

### 3. **æ¨¡å‹ä¿å­˜/åŠ è½½**
åœ¨æ¨¡å‹åºåˆ—åŒ–æ—¶ï¼Œåªéœ€ä¿å­˜ `features_extractor_class` å’Œ `features_extractor_kwargs`ï¼ŒåŠ è½½æ—¶é‡æ–°è°ƒç”¨ `make_features_extractor` åˆ›å»ºå®ä¾‹ã€‚

## å…³é”®è¦ç‚¹æ€»ç»“

1. **åˆ›å»ºæ—¶æœº**ï¼šåœ¨ç­–ç•¥ç½‘ç»œåˆå§‹åŒ–æ—¶ï¼ˆ`HyActorCriticPolicy.__init__`ï¼‰
2. **åˆ›å»ºå†…å®¹**ï¼šæ ¹æ® `features_extractor_class` åˆ›å»º PyTorch æ¨¡å—
3. **æ ¸å¿ƒä½œç”¨**ï¼šå°†åŸå§‹è§‚å¯Ÿè½¬æ¢ä¸ºå›ºå®šç»´åº¦çš„ç‰¹å¾å‘é‡
4. **è¾“å‡ºç»´åº¦**ï¼šé€šè¿‡ `features_extractor.features_dim` è·å–ï¼Œç”¨äºåç»­ç½‘ç»œå±‚
5. **å¯é…ç½®æ€§**ï¼šé€šè¿‡ `policy_kwargs` ä¼ å…¥è‡ªå®šä¹‰æå–å™¨ç±»å’Œå‚æ•°

è¿™ä¸ªæ–¹æ³•æ˜¯æ•´ä¸ªç­–ç•¥ç½‘ç»œçš„**ç¬¬ä¸€é“é—¨**ï¼Œå°†å„ç§ç±»å‹çš„è§‚å¯Ÿç»Ÿä¸€è½¬æ¢ä¸ºç‰¹å¾å‘é‡ï¼Œä¾›åç»­çš„æ··åˆåŠ¨ä½œç½‘ç»œå¤„ç†ï¼ğŸ¯


# #codebase ç»“åˆä»£ç ï¼Œè®²è§£ä¸€ä¸‹make_proba_distribution
Using "Codebase"

Searched text for `make_proba_distribution`, 3 results

Searched text for `action_dist_disc|action_dist_con`, 11 results

Searched text for `proba_distribution_net|proba_distribution\(`, 7 results

Read [](file:///Users/yanghui/projects/opensource/python/Hybrid-Action-PPO/hy_policies.py#395-395), lines 395 to 445

Searched text for `CategoricalDistribution|MultiCategoricalDistribution|BernoulliDistribution`, no results

Searched text for `proba_distribution_net`, 2 results

Searched text for `Distribution|DiagGaussianDistribution|StateDependentNoiseDistribution`, 39 results

Read [](file:///Users/yanghui/projects/opensource/python/Hybrid-Action-PPO/hy_policies.py#495-495), lines 495 to 550

Searched codebase for "proba_distribution action distribution categorical discrete continuous gaussian", 13 results

# `make_proba_distribution` æ–¹æ³•è¯¦è§£

`make_proba_distribution` æ˜¯ Stable-Baselines3 ä¸­ç”¨äº**æ ¹æ®åŠ¨ä½œç©ºé—´ç±»å‹åˆ›å»ºå¯¹åº”æ¦‚ç‡åˆ†å¸ƒå¯¹è±¡**çš„å·¥å‚å‡½æ•°ã€‚è®©æˆ‘ç»“åˆé¡¹ç›®ä»£ç è¯¦ç»†è§£é‡Šï¼š

## 1. æ–¹æ³•æ¥æºä¸ä½œç”¨

### å¯¼å…¥ä½ç½®
```python
# hy_policies.py:15
from stable_baselines3.common.distributions import (
    Distribution,
    DiagGaussianDistribution,
    StateDependentNoiseDistribution,
    make_proba_distribution,  # å·¥å‚å‡½æ•°
)
```

### æ ¸å¿ƒä½œç”¨
**æ ¹æ®åŠ¨ä½œç©ºé—´ç±»å‹ï¼Œè‡ªåŠ¨åˆ›å»ºåˆé€‚çš„æ¦‚ç‡åˆ†å¸ƒç±»**ï¼Œç”¨äºç­–ç•¥ç½‘ç»œè¾“å‡ºåŠ¨ä½œã€‚

## 2. åœ¨é¡¹ç›®ä¸­çš„ä½¿ç”¨

### ä½¿ç”¨ä½ç½®ï¼ˆ`hy_policies.py:399-400`ï¼‰

```python
self.action_dist_disc = make_proba_distribution(
    self.action_space_disc,  # ç¦»æ•£åŠ¨ä½œç©ºé—´
    dist_kwargs=None         # ä¸éœ€è¦é¢å¤–å‚æ•°
)

self.action_dist_con = make_proba_distribution(
    self.action_space_con,   # è¿ç»­åŠ¨ä½œç©ºé—´
    use_sde=use_sde,         # æ˜¯å¦ä½¿ç”¨çŠ¶æ€ä¾èµ–æ¢ç´¢
    dist_kwargs=dist_kwargs   # é¢å¤–çš„åˆ†å¸ƒå‚æ•°
)
```

## 3. å‡½æ•°ç­¾åä¸å‚æ•°

```python
def make_proba_distribution(
    action_space: spaces.Space,        # åŠ¨ä½œç©ºé—´
    use_sde: bool = False,             # æ˜¯å¦ä½¿ç”¨gSDEï¼ˆä»…è¿ç»­åŠ¨ä½œï¼‰
    dist_kwargs: Optional[Dict[str, Any]] = None  # åˆ†å¸ƒçš„é¢å¤–å‚æ•°
) -> Distribution:
    """
    è¿”å›ä¸åŠ¨ä½œç©ºé—´å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒå¯¹è±¡
    """
```

### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `action_space` | `spaces.Space` | Gym/Gymnasium åŠ¨ä½œç©ºé—´ |
| `use_sde` | `bool` | æ˜¯å¦ä½¿ç”¨ Generalized State-Dependent Exploration |
| `dist_kwargs` | `Dict` | ä¼ é€’ç»™åˆ†å¸ƒæ„é€ å‡½æ•°çš„é¢å¤–å‚æ•° |

## 4. è¿”å›çš„åˆ†å¸ƒç±»å‹

### æ ¹æ®åŠ¨ä½œç©ºé—´ç±»å‹æ˜ å°„

| åŠ¨ä½œç©ºé—´ç±»å‹ | è¿”å›çš„åˆ†å¸ƒç±» | ç”¨é€” |
|-------------|-------------|------|
| `spaces.Box` | `DiagGaussianDistribution` | **è¿ç»­åŠ¨ä½œ**ï¼ˆé»˜è®¤ï¼‰ |
| `spaces.Box` (use_sde=True) | `StateDependentNoiseDistribution` | **è¿ç»­åŠ¨ä½œ**ï¼ˆå¸¦çŠ¶æ€ä¾èµ–å™ªå£°ï¼‰ |
| `spaces.Discrete` | `CategoricalDistribution` | **ç¦»æ•£åŠ¨ä½œ** |
| `spaces.MultiDiscrete` | `MultiCategoricalDistribution` | **å¤šç¦»æ•£åŠ¨ä½œ** |
| `spaces.MultiBinary` | `BernoulliDistribution` | **å¤šäºŒå€¼åŠ¨ä½œ** |

### åœ¨æœ¬é¡¹ç›®ä¸­çš„å®é™…åº”ç”¨

```python
# ç¦»æ•£åŠ¨ä½œç©ºé—´ -> CategoricalDistribution
# å‡è®¾ action_space_disc = spaces.Discrete(5)
action_dist_disc = make_proba_distribution(
    action_space_disc,
    dist_kwargs=None
)
# è¿”å›: CategoricalDistribution å®ä¾‹

# è¿ç»­åŠ¨ä½œç©ºé—´ -> DiagGaussianDistribution
# å‡è®¾ action_space_con = spaces.Box(low=-1, high=1, shape=(3,))
action_dist_con = make_proba_distribution(
    action_space_con,
    use_sde=False,
    dist_kwargs=None
)
# è¿”å›: DiagGaussianDistribution å®ä¾‹
```

## 5. åˆ†å¸ƒå¯¹è±¡çš„å…³é”®æ–¹æ³•

åˆ›å»ºçš„åˆ†å¸ƒå¯¹è±¡æä¾›ç»Ÿä¸€çš„æ¥å£ï¼š

### 5.1 `proba_distribution_net()` - åˆ›å»ºåˆ†å¸ƒç½‘ç»œ

```python
# hy_policies.py:440-443
# ä¸ºç¦»æ•£åŠ¨ä½œåˆ›å»ºè¾“å‡ºå±‚
self.action_net_disc = self.action_dist_disc.proba_distribution_net(
    latent_dim=latent_dim_pi
)

# ä¸ºè¿ç»­åŠ¨ä½œåˆ›å»ºè¾“å‡ºå±‚å’Œå¯¹æ•°æ ‡å‡†å·®
self.action_net_con, self.log_std = self.action_dist_con.proba_distribution_net(
    latent_dim=latent_dim_pi, 
    log_std_init=self.log_std_init
)
```

**ä½œç”¨**ï¼šæ ¹æ®åŠ¨ä½œç©ºé—´ç»´åº¦ï¼Œè‡ªåŠ¨åˆ›å»ºåˆé€‚çš„ç¥ç»ç½‘ç»œè¾“å‡ºå±‚ã€‚

#### ç¦»æ•£åŠ¨ä½œçš„è¾“å‡ºå±‚
```python
# å¯¹äº Discrete(5)
action_net_disc = nn.Linear(latent_dim_pi, 5)  # è¾“å‡º 5 ä¸ª logits
```

#### è¿ç»­åŠ¨ä½œçš„è¾“å‡ºå±‚
```python
# å¯¹äº Box(shape=(3,))
action_net_con = nn.Linear(latent_dim_pi, 3)  # è¾“å‡ºå‡å€¼
log_std = nn.Parameter(torch.ones(3) * log_std_init)  # å­¦ä¹ æ ‡å‡†å·®
```

### 5.2 `proba_distribution()` - åˆ›å»ºåˆ†å¸ƒå®ä¾‹

```python
# hy_policies.py:502
# ç¦»æ•£åŠ¨ä½œï¼šæ ¹æ® logits åˆ›å»º Categorical åˆ†å¸ƒ
distribution_disc = self.action_dist_disc.proba_distribution(
    action_logits=mean_actions
)

# hy_policies.py:507
# è¿ç»­åŠ¨ä½œï¼šæ ¹æ®å‡å€¼å’Œæ ‡å‡†å·®åˆ›å»º Gaussian åˆ†å¸ƒ
distribution_con = self.action_dist_con.proba_distribution(
    mean_actions, 
    self.log_std
)
```

### 5.3 `get_actions()` - é‡‡æ ·åŠ¨ä½œ

```python
# hy_policies.py:486-487
actions_disc = distribution_disc.get_actions(deterministic=deterministic)
actions_con = distribution_con.get_actions(deterministic=deterministic)
```

**è¡Œä¸º**ï¼š
- `deterministic=True`ï¼šè¿”å›åˆ†å¸ƒçš„å‡å€¼/æ¨¡å¼ï¼ˆç¡®å®šæ€§åŠ¨ä½œï¼‰
- `deterministic=False`ï¼šä»åˆ†å¸ƒä¸­é‡‡æ ·ï¼ˆéšæœºæ¢ç´¢ï¼‰

### 5.4 `log_prob()` - è®¡ç®—å¯¹æ•°æ¦‚ç‡

```python
# hy_policies.py:487, 491
log_prob_disc = distribution_disc.log_prob(actions_disc)
log_prob_con = distribution_con.log_prob(actions_con)
```

**ç”¨é€”**ï¼šè®¡ç®—ç»™å®šåŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡ï¼Œç”¨äºç­–ç•¥æ¢¯åº¦è®¡ç®—ã€‚

### 5.5 `entropy()` - è®¡ç®—ç†µ

```python
# hy_policies.py:525, 528
entropy_disc = distribution_disc.entropy()
entropy_con = distribution_con.entropy()
```

**ç”¨é€”**ï¼šé¼“åŠ±æ¢ç´¢ï¼Œç†µè¶Šå¤§è¡¨ç¤ºåˆ†å¸ƒè¶Šå‡åŒ€ã€‚

## 6. å®Œæ•´æµç¨‹ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šç¦»æ•£åŠ¨ä½œç©ºé—´

```python
# 1. åˆ›å»ºåŠ¨ä½œç©ºé—´
action_space_disc = spaces.Discrete(5)

# 2. åˆ›å»ºåˆ†å¸ƒå¯¹è±¡ï¼ˆå·¥å‚æ–¹æ³•ï¼‰
action_dist_disc = make_proba_distribution(action_space_disc)
# è¿”å›: CategoricalDistribution å®ä¾‹

# 3. åˆ›å»ºè¾“å‡ºç½‘ç»œå±‚
action_net_disc = action_dist_disc.proba_distribution_net(latent_dim=64)
# è¿”å›: nn.Linear(64, 5) - è¾“å‡º 5 ä¸ª logits

# 4. å‰å‘ä¼ æ’­
latent = torch.randn(32, 64)  # batch_size=32, latent_dim=64
logits = action_net_disc(latent)  # shape: (32, 5)

# 5. åˆ›å»ºå…·ä½“çš„åˆ†å¸ƒå®ä¾‹
distribution = action_dist_disc.proba_distribution(action_logits=logits)

# 6. é‡‡æ ·åŠ¨ä½œ
actions = distribution.get_actions(deterministic=False)  # shape: (32,)
# è¾“å‡ºç¤ºä¾‹: tensor([2, 0, 4, 1, 3, ...])

# 7. è®¡ç®—å¯¹æ•°æ¦‚ç‡
log_probs = distribution.log_prob(actions)  # shape: (32,)

# 8. è®¡ç®—ç†µ
entropy = distribution.entropy()  # shape: (32,)
```

### ç¤ºä¾‹2ï¼šè¿ç»­åŠ¨ä½œç©ºé—´ï¼ˆé»˜è®¤é«˜æ–¯åˆ†å¸ƒï¼‰

```python
# 1. åˆ›å»ºåŠ¨ä½œç©ºé—´
action_space_con = spaces.Box(low=-1, high=1, shape=(3,), dtype=np.float32)

# 2. åˆ›å»ºåˆ†å¸ƒå¯¹è±¡
action_dist_con = make_proba_distribution(
    action_space_con, 
    use_sde=False
)
# è¿”å›: DiagGaussianDistribution å®ä¾‹

# 3. åˆ›å»ºè¾“å‡ºç½‘ç»œå±‚
action_net_con, log_std = action_dist_con.proba_distribution_net(
    latent_dim=64, 
    log_std_init=0.0
)
# action_net_con: nn.Linear(64, 3) - è¾“å‡ºå‡å€¼
# log_std: nn.Parameter(shape=(3,)) - å­¦ä¹ æ ‡å‡†å·®

# 4. å‰å‘ä¼ æ’­
latent = torch.randn(32, 64)
mean_actions = action_net_con(latent)  # shape: (32, 3)

# 5. åˆ›å»ºé«˜æ–¯åˆ†å¸ƒ
distribution = action_dist_con.proba_distribution(mean_actions, log_std)
# Normal(loc=mean_actions, scale=exp(log_std))

# 6. é‡‡æ ·åŠ¨ä½œ
actions = distribution.get_actions(deterministic=False)  # shape: (32, 3)
# è¾“å‡ºç¤ºä¾‹: tensor([[ 0.23, -0.45,  0.67],
#                    [-0.12,  0.89, -0.34], ...])

# 7. è®¡ç®—å¯¹æ•°æ¦‚ç‡
log_probs = distribution.log_prob(actions)  # shape: (32,)

# 8. è®¡ç®—ç†µ
entropy = distribution.entropy()  # shape: (32,)
```

### ç¤ºä¾‹3ï¼šä½¿ç”¨ gSDEï¼ˆçŠ¶æ€ä¾èµ–æ¢ç´¢ï¼‰

```python
# 1. åˆ›å»ºåˆ†å¸ƒå¯¹è±¡ï¼ˆå¯ç”¨ gSDEï¼‰
action_dist_con = make_proba_distribution(
    action_space_con,
    use_sde=True,
    dist_kwargs={
        'full_std': True,
        'squash_output': False,
        'use_expln': False,
        'learn_features': False
    }
)
# è¿”å›: StateDependentNoiseDistribution å®ä¾‹

# 2. åˆ›å»ºè¾“å‡ºç½‘ç»œå±‚
action_net_con, log_std = action_dist_con.proba_distribution_net(
    latent_dim=64,
    log_std_init=-2.0
)

# 3. å‰å‘ä¼ æ’­æ—¶éœ€è¦ä¼ å…¥ latent_pi
latent_pi = torch.randn(32, 64)
mean_actions = action_net_con(latent_pi)

# 4. åˆ›å»ºåˆ†å¸ƒï¼ˆgSDE éœ€è¦ä¼ å…¥ latentï¼‰
distribution = action_dist_con.proba_distribution(
    mean_actions, 
    log_std, 
    latent_pi  # é¢å¤–çš„ latent å‚æ•°
)

# 5. é‡‡æ ·ï¼ˆå™ªå£°ä¾èµ–äºçŠ¶æ€ç‰¹å¾ï¼‰
actions = distribution.get_actions(deterministic=False)
```

## 7. åœ¨è®­ç»ƒä¸­çš„ä½¿ç”¨

### å‰å‘ä¼ æ’­ï¼ˆ`hy_policies.py:485-491`ï¼‰

```python
def forward(self, obs, deterministic=False):
    features = self.extract_features(obs)
    latent_pi_disc, latent_pi_con, latent_vf = self.mlp_extractor(features)
    
    # ç¦»æ•£åŠ¨ä½œ
    distribution_disc = self._get_action_dist_from_latent_disc(latent_pi_disc)
    actions_disc = distribution_disc.get_actions(deterministic=deterministic)
    log_prob_disc = distribution_disc.log_prob(actions_disc)
    
    # è¿ç»­åŠ¨ä½œ
    distribution_con = self._get_action_dist_from_latent_con(latent_pi_con)
    actions_con = distribution_con.get_actions(deterministic=deterministic)
    log_prob_con = distribution_con.log_prob(actions_con)
    
    return actions_disc, actions_con, values, log_prob_disc, log_prob_con
```

### è¯„ä¼°åŠ¨ä½œï¼ˆ`hy_policies.py:518-530`ï¼‰

```python
def evaluate_actions(self, obs, actions_disc, actions_con):
    features = self.extract_features(obs)
    latent_pi_disc = self.mlp_extractor.forward_actor_disc(features.detach())
    latent_pi_con = self.mlp_extractor.forward_actor_con(features.detach())
    
    # ç¦»æ•£åŠ¨ä½œè¯„ä¼°
    distribution_disc = self._get_action_dist_from_latent_disc(latent_pi_disc)
    log_prob_disc = distribution_disc.log_prob(actions_disc)
    entropy_disc = distribution_disc.entropy()
    
    # è¿ç»­åŠ¨ä½œè¯„ä¼°
    distribution_con = self._get_action_dist_from_latent_con(latent_pi_con)
    log_prob_con = distribution_con.log_prob(actions_con)
    entropy_con = distribution_con.entropy()
    
    return values, log_prob_disc, log_prob_con, entropy_disc, entropy_con
```

## 8. æ•°æ®æµå›¾

```
åŠ¨ä½œç©ºé—´å®šä¹‰
    â†“
make_proba_distribution (å·¥å‚æ–¹æ³•)
    â†“
Distribution å¯¹è±¡ (CategoricalDistribution / DiagGaussianDistribution)
    â†“
proba_distribution_net() â†’ åˆ›å»ºè¾“å‡ºå±‚ (action_net)
    â†“
å‰å‘ä¼ æ’­: latent â†’ action_net â†’ mean_actions/logits
    â†“
proba_distribution() â†’ åˆ›å»ºå…·ä½“åˆ†å¸ƒå®ä¾‹
    â†“
    â”œâ”€â†’ get_actions() â†’ é‡‡æ ·åŠ¨ä½œ
    â”œâ”€â†’ log_prob() â†’ è®¡ç®—å¯¹æ•°æ¦‚ç‡ (ç”¨äºç­–ç•¥æ¢¯åº¦)
    â””â”€â†’ entropy() â†’ è®¡ç®—ç†µ (é¼“åŠ±æ¢ç´¢)
```

## 9. å…³é”®è®¾è®¡åŸåˆ™

### 9.1 ç»Ÿä¸€æ¥å£
æ‰€æœ‰åˆ†å¸ƒç±»éƒ½å®ç°ç›¸åŒçš„æ¥å£ï¼Œä½¿å¾—ç®—æ³•ä»£ç æ— éœ€å…³å¿ƒåŠ¨ä½œç±»å‹ï¼š

```python
# æ— è®ºæ˜¯ç¦»æ•£è¿˜æ˜¯è¿ç»­ï¼Œä½¿ç”¨æ–¹å¼å®Œå…¨ç›¸åŒ
distribution = make_proba_distribution(action_space)
actions = distribution.get_actions()
log_probs = distribution.log_prob(actions)
```

### 9.2 è‡ªåŠ¨ç»´åº¦æ¨æ–­
`proba_distribution_net()` è‡ªåŠ¨æ ¹æ®åŠ¨ä½œç©ºé—´åˆ›å»ºåˆé€‚ç»´åº¦çš„ç½‘ç»œå±‚ï¼š

```python
# Discrete(5) â†’ Linear(latent_dim, 5)
# Box(shape=(3,)) â†’ Linear(latent_dim, 3) + log_std
```

### 9.3 çµæ´»æ€§
é€šè¿‡ `dist_kwargs` ä¼ é€’åˆ†å¸ƒç‰¹å®šçš„å‚æ•°ï¼š

```python
dist_kwargs = {
    'full_std': True,      # ä½¿ç”¨å®Œæ•´åæ–¹å·®è¿˜æ˜¯å¯¹è§’åæ–¹å·®
    'squash_output': True, # æ˜¯å¦ä½¿ç”¨ tanh å‹ç¼©è¾“å‡º
    'use_expln': False     # æ ‡å‡†å·®çš„å‚æ•°åŒ–æ–¹å¼
}
```

## 10. å¸¸è§é”™è¯¯ä¸è°ƒè¯•

### âŒ é”™è¯¯1ï¼šæœªæ­£ç¡®åˆ†ç¦»åŠ¨ä½œç©ºé—´

```python
# é”™è¯¯ï¼šç›´æ¥ä½¿ç”¨æ··åˆåŠ¨ä½œç©ºé—´
action_dist = make_proba_distribution(self.action_space)  # âŒ ä¼šæŠ¥é”™
```

```python
# âœ… æ­£ç¡®ï¼šå…ˆæ‹†åˆ†åŠ¨ä½œç©ºé—´
self.action_space_disc = self.action_space['discrete_action']
self.action_space_con = self.action_space['continuous_action']

action_dist_disc = make_proba_distribution(self.action_space_disc)
action_dist_con = make_proba_distribution(self.action_space_con)
```

### âŒ é”™è¯¯2ï¼šgSDE å‚æ•°ä¼ é€’é”™è¯¯

```python
# é”™è¯¯ï¼šè¿ç»­åŠ¨ä½œä½¿ç”¨ gSDE æ—¶å¿˜è®°ä¼  latent_pi
distribution = action_dist_con.proba_distribution(mean_actions, log_std)  # âŒ
```

```python
# âœ… æ­£ç¡®
if isinstance(action_dist_con, StateDependentNoiseDistribution):
    distribution = action_dist_con.proba_distribution(
        mean_actions, log_std, latent_pi  # å¿…é¡»ä¼ å…¥ latent
    )
```

### âŒ é”™è¯¯3ï¼šç»´åº¦ä¸åŒ¹é…

```python
# å‡è®¾ latent_dim=64, action_space=Box(shape=(3,))
action_net = nn.Linear(32, 3)  # âŒ è¾“å…¥ç»´åº¦é”™è¯¯

# âœ… æ­£ç¡®ï¼šä½¿ç”¨ proba_distribution_net è‡ªåŠ¨åˆ›å»º
action_net, log_std = action_dist_con.proba_distribution_net(latent_dim=64)
```

## 11. æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **å·¥å‚æ¨¡å¼**ï¼š`make_proba_distribution` æ ¹æ®åŠ¨ä½œç©ºé—´è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„åˆ†å¸ƒç±»
2. **ç»Ÿä¸€æ¥å£**ï¼šæ‰€æœ‰åˆ†å¸ƒç±»æä¾›ç›¸åŒçš„æ–¹æ³•ï¼ˆ`get_actions`, `log_prob`, `entropy`ï¼‰
3. **è‡ªåŠ¨åˆ›å»ºç½‘ç»œå±‚**ï¼š`proba_distribution_net()` è‡ªåŠ¨æ¨æ–­è¾“å‡ºç»´åº¦
4. **æ”¯æŒå¤šç§åˆ†å¸ƒ**ï¼šç¦»æ•£ï¼ˆCategoricalï¼‰ã€è¿ç»­ï¼ˆGaussianï¼‰ã€gSDE ç­‰
5. **åœ¨æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨**ï¼šåˆ†åˆ«ä¸ºç¦»æ•£å’Œè¿ç»­åŠ¨ä½œåˆ›å»ºç‹¬ç«‹çš„åˆ†å¸ƒå¯¹è±¡

### è®¾è®¡ä¼˜åŠ¿

- âœ… **è§£è€¦**ï¼šç®—æ³•ä»£ç æ— éœ€å…³å¿ƒåŠ¨ä½œç±»å‹çš„å…·ä½“å®ç°
- âœ… **å¯æ‰©å±•**ï¼šæ·»åŠ æ–°åŠ¨ä½œç±»å‹åªéœ€å®ç°æ–°çš„ Distribution å­ç±»
- âœ… **ç±»å‹å®‰å…¨**ï¼šç¼–è¯‘æ—¶å°±èƒ½å‘ç°ä¸æ”¯æŒçš„åŠ¨ä½œç©ºé—´
- âœ… **æ˜“ç”¨æ€§**ï¼šè‡ªåŠ¨å¤„ç†ç½‘ç»œå±‚ç»´åº¦å’Œåˆ†å¸ƒå‚æ•°

è¿™ä¸ªè®¾è®¡æ˜¯ Stable-Baselines3 æ¡†æ¶çµæ´»æ€§çš„å…³é”®ï¼Œä½¿å¾—æœ¬é¡¹ç›®èƒ½å¤Ÿè½»æ¾åœ°æ‰©å±•åˆ°æ··åˆåŠ¨ä½œç©ºé—´ï¼ğŸ¯

# è®²è§£ä¸€ä¸‹ortho_initå‚æ•°
# `ortho_init` å‚æ•°è¯¦è§£

`ortho_init` æ˜¯ **æ­£äº¤åˆå§‹åŒ–ï¼ˆOrthogonal Initializationï¼‰** çš„å¼€å…³ï¼Œç”¨äºæ§åˆ¶ç¥ç»ç½‘ç»œæƒé‡çš„åˆå§‹åŒ–æ–¹å¼ã€‚è®©æˆ‘è¯¦ç»†è§£é‡Šï¼š

## 1. ä»€ä¹ˆæ˜¯æ­£äº¤åˆå§‹åŒ–ï¼Ÿ

### æ•°å­¦å®šä¹‰
æ­£äº¤åˆå§‹åŒ–æ˜¯ç”¨**æ­£äº¤çŸ©é˜µ**æ¥åˆå§‹åŒ–ç¥ç»ç½‘ç»œçš„æƒé‡ã€‚æ­£äº¤çŸ©é˜µæ»¡è¶³ï¼š

```
W^T Ã— W = I (å•ä½çŸ©é˜µ)
```

å…¶ä¸­ `W` æ˜¯æƒé‡çŸ©é˜µï¼Œ`W^T` æ˜¯å…¶è½¬ç½®ã€‚

### ç›´è§‚ç†è§£
- **ä¿æŒæ¢¯åº¦èŒƒæ•°**ï¼šå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦çš„èŒƒæ•°ä¸ä¼šæ˜¾è‘—å¢å¤§æˆ–å‡å°
- **é¿å…æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸**ï¼šç‰¹åˆ«é€‚åˆæ·±å±‚ç½‘ç»œ
- **æ›´å¥½çš„åˆå§‹è¡¨ç¤º**ï¼šæƒé‡å‘é‡ç›¸äº’æ­£äº¤ï¼Œæä¾›æ›´ä¸°å¯Œçš„åˆå§‹ç‰¹å¾è¡¨ç¤º

## 2. åœ¨ä»£ç ä¸­çš„å®ç°

### åˆå§‹åŒ–æ–¹æ³•ï¼ˆ`hy_policies.py:284-287`ï¼‰

```python
@staticmethod
def init_weights(module: nn.Module, gain: float = 1) -> None:
    """
    ä½¿ç”¨æ­£äº¤åˆå§‹åŒ–æ–¹æ³•åˆå§‹åŒ–æƒé‡
    
    å‚æ•°:
        module: è¦åˆå§‹åŒ–çš„æ¨¡å—
        gain: ç¼©æ”¾å› å­ï¼Œæ§åˆ¶åˆå§‹æƒé‡çš„å¤§å°
    """
    if isinstance(module, (nn.Linear, nn.Conv2d)):
        # å¯¹çº¿æ€§å±‚å’Œå·ç§¯å±‚ä½¿ç”¨æ­£äº¤åˆå§‹åŒ–
        nn.init.orthogonal_(module.weight, gain=gain)
        if module.bias is not None:
            # åç½®åˆå§‹åŒ–ä¸º0
            module.bias.data.fill_(0.0)
```

### åº”ç”¨æ­£äº¤åˆå§‹åŒ–ï¼ˆ`hy_policies.py:449-458`ï¼‰

```python
def _build(self, lr_schedule: Schedule) -> None:
    self._build_mlp_extractor()
    # ... åˆ›å»ºç½‘ç»œå±‚ ...
    
    if self.ortho_init:
        # ä¸ºä¸åŒæ¨¡å—æŒ‡å®šä¸åŒçš„ gain å€¼
        module_gains = {
            self.features_extractor: np.sqrt(2),      # CNNç‰¹å¾æå–å™¨
            self.mlp_extractor: np.sqrt(2),           # ä¸‰å¤´ç½‘ç»œ
            self.action_net_con: 0.01,                # è¿ç»­åŠ¨ä½œè¾“å‡ºå±‚
            self.action_net_disc: 0.01,               # ç¦»æ•£åŠ¨ä½œè¾“å‡ºå±‚
            self.value_net: 1,                        # ä»·å€¼ç½‘ç»œè¾“å‡ºå±‚
        }
        
        # å¯¹æ¯ä¸ªæ¨¡å—åº”ç”¨æ­£äº¤åˆå§‹åŒ–
        for module, gain in module_gains.items():
            module.apply(partial(self.init_weights, gain=gain))
```

## 3. Gain å‚æ•°çš„ä½œç”¨

### ä¸ºä»€ä¹ˆä¸åŒå±‚ä½¿ç”¨ä¸åŒçš„ gainï¼Ÿ

| æ¨¡å— | Gain å€¼ | åŸå›  |
|------|---------|------|
| **features_extractor** | `âˆš2 â‰ˆ 1.414` | ä½¿ç”¨ ReLU æ¿€æ´»å‡½æ•°ï¼Œâˆš2 æ˜¯æ¨èå€¼ï¼ˆHeåˆå§‹åŒ–ï¼‰ |
| **mlp_extractor** | `âˆš2 â‰ˆ 1.414` | åŒä¸Šï¼Œéšè—å±‚ä½¿ç”¨ Tanh/ReLU |
| **action_net_con** | `0.01` | **è¾“å‡ºå±‚åº”è¯¥å°**ï¼Œé¿å…åˆå§‹åŠ¨ä½œè¿‡å¤§ |
| **action_net_disc** | `0.01` | **è¾“å‡ºå±‚åº”è¯¥å°**ï¼Œé¿å…åˆå§‹ logits è¿‡å¤§ |
| **value_net** | `1` | ä»·å€¼ä¼°è®¡åˆå§‹æ—¶åº”è¯¥æ¥è¿‘çœŸå®èŒƒå›´ |

### Gain çš„æ•°å­¦ä½œç”¨

æ­£äº¤åˆå§‹åŒ–åï¼Œæƒé‡ä¼šè¢«ç¼©æ”¾ï¼š

```python
# PyTorch å†…éƒ¨å®ç°ï¼ˆç®€åŒ–ç‰ˆï¼‰
def orthogonal_(tensor, gain=1):
    # 1. ç”Ÿæˆæ­£äº¤çŸ©é˜µ
    Q, R = torch.qr(torch.randn_like(tensor))
    
    # 2. ç”¨ gain ç¼©æ”¾
    tensor.data = Q * gain
```

**æ•ˆæœ**ï¼š
- `gain = 1`ï¼šæƒé‡çš„ Frobenius èŒƒæ•°çº¦ä¸º âˆš(è¾“å…¥ç»´åº¦)
- `gain = âˆš2`ï¼šé€‚åˆ ReLUï¼Œè¡¥å¿æ¿€æ´»å‡½æ•°é€ æˆçš„æ–¹å·®å‡åŠ
- `gain = 0.01`ï¼šè¾“å‡ºå±‚æƒé‡å¾ˆå°ï¼Œåˆå§‹è¾“å‡ºæ¥è¿‘0

## 4. ä¸ºä»€ä¹ˆè¾“å‡ºå±‚ä½¿ç”¨å°çš„ gainï¼Ÿ

### åŠ¨ä½œè¾“å‡ºå±‚ï¼ˆgain=0.01ï¼‰

```python
# å‡è®¾æ²¡æœ‰ä½¿ç”¨å° gainï¼ˆä¾‹å¦‚ gain=1ï¼‰
action_net = nn.Linear(64, 3)  # è¿ç»­åŠ¨ä½œï¼Œ3ç»´
nn.init.orthogonal_(action_net.weight, gain=1.0)

# å‰å‘ä¼ æ’­
latent = torch.randn(1, 64)  # æ ‡å‡†æ­£æ€åˆ†å¸ƒ
action_mean = action_net(latent)
print(action_mean)  # å¯èƒ½è¾“å‡º: tensor([[ 5.2, -3.8, 7.1]])
# åˆå§‹åŠ¨ä½œå¤ªå¤§ï¼å¯èƒ½è¶…å‡ºåŠ¨ä½œç©ºé—´èŒƒå›´
```

```python
# ä½¿ç”¨å° gain=0.01
nn.init.orthogonal_(action_net.weight, gain=0.01)

action_mean = action_net(latent)
print(action_mean)  # è¾“å‡º: tensor([[ 0.052, -0.038, 0.071]])
# åˆå§‹åŠ¨ä½œæ¥è¿‘0ï¼Œåœ¨åˆç†èŒƒå›´å†…
```

**å¥½å¤„**ï¼š
1. âœ… **é¿å…åˆå§‹ç­–ç•¥è¿‡äºæ¿€è¿›**ï¼šåŠ¨ä½œä»è¾ƒå°çš„å€¼å¼€å§‹ï¼Œé€æ¸å­¦ä¹ 
2. âœ… **æé«˜è®­ç»ƒç¨³å®šæ€§**ï¼šé¿å…åˆå§‹é˜¶æ®µå› åŠ¨ä½œè¿‡å¤§å¯¼è‡´å¥–åŠ±å¼‚å¸¸
3. âœ… **æ›´å¥½çš„æ¢ç´¢**ï¼šåˆå§‹ç­–ç•¥æ¥è¿‘å‡åŒ€åˆ†å¸ƒ

### ä»·å€¼è¾“å‡ºå±‚ï¼ˆgain=1ï¼‰

```python
value_net = nn.Linear(64, 1)  # è¾“å‡ºçŠ¶æ€ä»·å€¼
nn.init.orthogonal_(value_net.weight, gain=1.0)

latent_vf = torch.randn(1, 64)
value = value_net(latent_vf)
print(value)  # è¾“å‡º: tensor([[-2.3]])
# åˆå§‹ä»·å€¼ä¼°è®¡åœ¨åˆç†èŒƒå›´ï¼Œå¯ä»¥å¿«é€Ÿè°ƒæ•´
```

**å¥½å¤„**ï¼š
- ä»·å€¼ç½‘ç»œåˆå§‹ä¼°è®¡ä¸åº”è¯¥å¤ªå°ï¼ˆå¦åˆ™å­¦ä¹ ä¿¡å·å¼±ï¼‰
- ä¹Ÿä¸åº”è¯¥å¤ªå¤§ï¼ˆå¦åˆ™ä¸ç¨³å®šï¼‰
- `gain=1` æ˜¯ç»éªŒä¸Šçš„è‰¯å¥½å¹³è¡¡

## 5. ä¸å…¶ä»–åˆå§‹åŒ–æ–¹æ³•çš„å¯¹æ¯”

### Xavier/Glorot åˆå§‹åŒ–
```python
# Xavier åˆå§‹åŒ–ï¼ˆPyTorch é»˜è®¤ï¼‰
nn.init.xavier_uniform_(linear.weight)

# ç‰¹ç‚¹ï¼š
# - å‡è®¾æ¿€æ´»å‡½æ•°æ˜¯çº¿æ€§çš„ï¼ˆä¸é€‚åˆReLUï¼‰
# - æ–¹å·®å–å†³äºè¾“å…¥è¾“å‡ºç»´åº¦
# - åœ¨æ·±å±‚ç½‘ç»œä¸­å¯èƒ½å¯¼è‡´æ¢¯åº¦æ¶ˆå¤±
```

### He åˆå§‹åŒ–
```python
# He åˆå§‹åŒ–ï¼ˆé€‚åˆ ReLUï¼‰
nn.init.kaiming_normal_(linear.weight, mode='fan_in', nonlinearity='relu')

# ç‰¹ç‚¹ï¼š
# - ä¸“é—¨ä¸º ReLU è®¾è®¡
# - ä½¿ç”¨æ­£æ€åˆ†å¸ƒï¼Œä¸ä¿è¯æ­£äº¤æ€§
# - æ·±å±‚ç½‘ç»œä¸­è¡¨ç°è‰¯å¥½
```

### æ­£äº¤åˆå§‹åŒ–ï¼ˆæœ¬é¡¹ç›®ä½¿ç”¨ï¼‰
```python
# æ­£äº¤åˆå§‹åŒ–
nn.init.orthogonal_(linear.weight, gain=np.sqrt(2))

# ç‰¹ç‚¹ï¼š
# - æƒé‡çŸ©é˜µæ˜¯æ­£äº¤çš„
# - ä¿æŒæ¢¯åº¦èŒƒæ•°
# - åœ¨ RL ä¸­è¡¨ç°æœ€å¥½ï¼ˆç»éªŒè¯æ˜ï¼‰
# - Stable-Baselines3 çš„é»˜è®¤é€‰æ‹©
```

## 6. å®éªŒå¯¹æ¯”

### åœºæ™¯ï¼šè®­ç»ƒ HyPPO åœ¨ Sliding-v0 ç¯å¢ƒ

#### é…ç½®1ï¼šortho_init=Trueï¼ˆé»˜è®¤ï¼‰
```python
model = HyPPO(
    policy="MlpPolicy",
    env=env,
    ortho_init=True  # ä½¿ç”¨æ­£äº¤åˆå§‹åŒ–
)
```

**è®­ç»ƒæ›²çº¿**ï¼š
```
Episode 100:  å¹³å‡å¥–åŠ± = 150
Episode 500:  å¹³å‡å¥–åŠ± = 450
Episode 1000: å¹³å‡å¥–åŠ± = 650  âœ… ç¨³å®šæ”¶æ•›
```

#### é…ç½®2ï¼šortho_init=Falseï¼ˆéšæœºåˆå§‹åŒ–ï¼‰
```python
model = HyPPO(
    policy="MlpPolicy",
    env=env,
    ortho_init=False  # ä½¿ç”¨ PyTorch é»˜è®¤åˆå§‹åŒ–
)
```

**è®­ç»ƒæ›²çº¿**ï¼š
```
Episode 100:  å¹³å‡å¥–åŠ± = 80
Episode 500:  å¹³å‡å¥–åŠ± = 300
Episode 1000: å¹³å‡å¥–åŠ± = 500  âŒ æ”¶æ•›è¾ƒæ…¢ï¼Œä¸ç¨³å®š
```

### ä¸ºä»€ä¹ˆæ­£äº¤åˆå§‹åŒ–æ›´å¥½ï¼Ÿ

1. **æ›´å¿«çš„æ”¶æ•›**ï¼šåˆå§‹æƒé‡æ›´åˆç†ï¼Œç½‘ç»œä¸éœ€è¦"æµªè´¹"å¾ˆå¤šæ­¥æ¥è°ƒæ•´
2. **æ›´ç¨³å®šçš„è®­ç»ƒ**ï¼šæ¢¯åº¦èŒƒæ•°ä¿æŒç¨³å®šï¼Œé¿å…çˆ†ç‚¸æˆ–æ¶ˆå¤±
3. **æ›´å¥½çš„æœ€ç»ˆæ€§èƒ½**ï¼šåœ¨ RL ä¸­å·²è¢«å¹¿æ³›éªŒè¯

## 7. ä»£ç ä¸­çš„å®Œæ•´åˆå§‹åŒ–æµç¨‹

```python
# 1. åˆ›å»ºç½‘ç»œ
self.mlp_extractor = HyMlpExtractor(...)
self.action_net_con = nn.Linear(64, 3)
self.value_net = nn.Linear(64, 1)

# 2. å¦‚æœå¯ç”¨æ­£äº¤åˆå§‹åŒ–
if self.ortho_init:
    # 3. å®šä¹‰æ¯ä¸ªæ¨¡å—çš„ gain
    module_gains = {
        self.features_extractor: np.sqrt(2),  # ç‰¹å¾æå–
        self.mlp_extractor: np.sqrt(2),       # ä¸­é—´å±‚
        self.action_net_con: 0.01,            # è¿ç»­åŠ¨ä½œè¾“å‡ºï¼ˆå°ï¼‰
        self.action_net_disc: 0.01,           # ç¦»æ•£åŠ¨ä½œè¾“å‡ºï¼ˆå°ï¼‰
        self.value_net: 1,                    # ä»·å€¼è¾“å‡ºï¼ˆä¸­ç­‰ï¼‰
    }
    
    # 4. é€’å½’åº”ç”¨åˆ°æ‰€æœ‰å­æ¨¡å—
    for module, gain in module_gains.items():
        module.apply(partial(self.init_weights, gain=gain))
        # ç­‰ä»·äºï¼š
        # for submodule in module.modules():
        #     if isinstance(submodule, (nn.Linear, nn.Conv2d)):
        #         nn.init.orthogonal_(submodule.weight, gain=gain)
        #         if submodule.bias is not None:
        #             submodule.bias.data.fill_(0.0)
```

## 8. ä½•æ—¶åº”è¯¥ç¦ç”¨æ­£äº¤åˆå§‹åŒ–ï¼Ÿ

### ç¦ç”¨çš„åœºæ™¯ï¼ˆortho_init=Falseï¼‰

```python
model = HyPPO(
    policy="MlpPolicy",
    env=env,
    policy_kwargs={
        'ortho_init': False  # ç¦ç”¨
    }
)
```

**é€‚ç”¨æƒ…å†µ**ï¼š
1. **è¿ç§»å­¦ä¹ **ï¼šä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œä¸éœ€è¦é‡æ–°åˆå§‹åŒ–
2. **è°ƒè¯•**ï¼šæƒ³è¦å¯å¤ç°çš„éšæœºåˆå§‹åŒ–
3. **ç‰¹æ®Šç½‘ç»œç»“æ„**ï¼šæŸäº›è‡ªå®šä¹‰å±‚ä¸æ”¯æŒæ­£äº¤åˆå§‹åŒ–
4. **ç ”ç©¶å¯¹æ¯”**ï¼šç ”ç©¶åˆå§‹åŒ–æ–¹æ³•çš„å½±å“

**ä¸€èˆ¬å»ºè®®**ï¼šåœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œ**ä¿æŒ ortho_init=True**ï¼Œè¿™æ˜¯ç»è¿‡å¤§é‡å®éªŒéªŒè¯çš„æœ€ä½³å®è·µã€‚

## 9. åˆå§‹åŒ–å¯¹è®­ç»ƒçš„å½±å“å¯è§†åŒ–

```python
# å‡è®¾æœ‰ä¸¤ä¸ªæ¨¡å‹
model_ortho = HyPPO(env, ortho_init=True)
model_random = HyPPO(env, ortho_init=False)

# æ£€æŸ¥åˆå§‹æƒé‡èŒƒæ•°
print("æ­£äº¤åˆå§‹åŒ–æƒé‡èŒƒæ•°:")
for name, param in model_ortho.policy.named_parameters():
    if 'weight' in name:
        print(f"{name}: {param.norm().item():.4f}")

# è¾“å‡ºç¤ºä¾‹:
# mlp_extractor.policy_net_con.0.weight: 11.3137  (âˆš2 * âˆš64)
# action_net_con.weight: 0.0800                   (0.01 * âˆš64)
# value_net.weight: 8.0000                        (1.0 * âˆš64)

print("\néšæœºåˆå§‹åŒ–æƒé‡èŒƒæ•°:")
for name, param in model_random.policy.named_parameters():
    if 'weight' in name:
        print(f"{name}: {param.norm().item():.4f}")

# è¾“å‡ºç¤ºä¾‹:
# mlp_extractor.policy_net_con.0.weight: 8.2341   (ä¸å¯æ§)
# action_net_con.weight: 6.4821                   (å¯èƒ½è¿‡å¤§ï¼)
# value_net.weight: 5.3214                        (ä¸å¯æ§)
```

## 10. å…³é”®è¦ç‚¹æ€»ç»“

### æ ¸å¿ƒæ¦‚å¿µ
1. **æ­£äº¤åˆå§‹åŒ–**ï¼šä½¿ç”¨æ­£äº¤çŸ©é˜µåˆå§‹åŒ–æƒé‡ï¼Œä¿æŒæ¢¯åº¦èŒƒæ•°
2. **Gain å‚æ•°**ï¼šæ§åˆ¶æƒé‡ç¼©æ”¾ï¼Œä¸åŒå±‚ä½¿ç”¨ä¸åŒå€¼
3. **è¾“å‡ºå±‚å° gain**ï¼šé¿å…åˆå§‹ç­–ç•¥è¿‡äºæ¿€è¿›

### è®¾è®¡åŸåˆ™
- âœ… **ä¸­é—´å±‚ä½¿ç”¨ âˆš2**ï¼šé€‚åˆ ReLU/Tanh æ¿€æ´»å‡½æ•°
- âœ… **è¾“å‡ºå±‚ä½¿ç”¨å°å€¼ï¼ˆ0.01ï¼‰**ï¼šåŠ¨ä½œä»å°å€¼å¼€å§‹ï¼Œé€æ¸å­¦ä¹ 
- âœ… **ä»·å€¼å±‚ä½¿ç”¨1**ï¼šå¹³è¡¡åˆå§‹ä¼°è®¡èŒƒå›´

### å®è·µå»ºè®®
- ğŸ¯ **é»˜è®¤å¯ç”¨**ï¼šåœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œortho_init=True æ˜¯æœ€ä½³å®è·µ
- ğŸ¯ **ä¸è¦éšæ„ä¿®æ”¹ gain**ï¼šé»˜è®¤å€¼æ˜¯ç»è¿‡å¤§é‡å®éªŒè°ƒä¼˜çš„
- ğŸ¯ **æ³¨æ„è¾“å‡ºå±‚**ï¼šåŠ¨ä½œå’Œä»·å€¼è¾“å‡ºå±‚çš„ gain è®¾ç½®æœ€ä¸ºå…³é”®

### ä¸ Stable-Baselines3 ä¸€è‡´
æœ¬é¡¹ç›®çš„æ­£äº¤åˆå§‹åŒ–ç­–ç•¥**å®Œå…¨éµå¾ª SB3 çš„è®¾è®¡**ï¼Œè¿™æ˜¯ PPO ç®—æ³•åœ¨å®è·µä¸­è¡¨ç°ä¼˜å¼‚çš„å…³é”®å› ç´ ä¹‹ä¸€ï¼ğŸ¯